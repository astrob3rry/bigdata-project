{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import openpyxl\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snapy import MinHash, LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method\n",
    "#### Use edit distance or levestein distance or LCS to check whether column names are common\n",
    "#### Use sampling to check zipcode and address\n",
    "#### Jaccard Similarity, and using Prefix Indexing? I don't think this is quite neccessary since the string is not long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input path\n",
    "input_path = os.path.join(os.getcwd(), \"data\")\n",
    "# output path\n",
    "output_path = os.path.join(os.getcwd(), \"out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hewei\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(input_path, \"yellow_tripdata.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-06-01 00:31:23</td>\n",
       "      <td>2020-06-01 00:49:58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>140</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>23.30</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-06-01 00:42:50</td>\n",
       "      <td>2020-06-01 01:04:33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>226</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25.30</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-06-01 00:39:51</td>\n",
       "      <td>2020-06-01 00:49:09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>116</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-06-01 00:56:13</td>\n",
       "      <td>2020-06-01 01:11:38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>141</td>\n",
       "      <td>116</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21.30</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-06-01 00:16:41</td>\n",
       "      <td>2020-06-01 00:29:30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21.95</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0       1.0  2020-06-01 00:31:23   2020-06-01 00:49:58              1.0   \n",
       "1       1.0  2020-06-01 00:42:50   2020-06-01 01:04:33              1.0   \n",
       "2       1.0  2020-06-01 00:39:51   2020-06-01 00:49:09              1.0   \n",
       "3       1.0  2020-06-01 00:56:13   2020-06-01 01:11:38              1.0   \n",
       "4       1.0  2020-06-01 00:16:41   2020-06-01 00:29:30              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0            3.6         1.0                  N           140            68   \n",
       "1            5.6         1.0                  N            79           226   \n",
       "2            2.3         1.0                  N           238           116   \n",
       "3            5.3         1.0                  N           141           116   \n",
       "4            4.4         1.0                  N           186            75   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0           1.0         15.5    3.0      0.5        4.00           0.0   \n",
       "1           1.0         19.5    3.0      0.5        2.00           0.0   \n",
       "2           2.0         10.0    0.5      0.5        0.00           0.0   \n",
       "3           2.0         17.5    3.0      0.5        0.00           0.0   \n",
       "4           1.0         14.5    3.0      0.5        3.65           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  \n",
       "0                    0.3         23.30                   2.5  \n",
       "1                    0.3         25.30                   2.5  \n",
       "2                    0.3         11.30                   0.0  \n",
       "3                    0.3         21.30                   2.5  \n",
       "4                    0.3         21.95                   2.5  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"VendorID\"].dtype == object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'tpep_pickup_datetime',\n",
       " 'tpep_dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'RatecodeID',\n",
       " 'store_and_fwd_flag',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'congestion_surcharge']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oo'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" oo \".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Settings:\n",
    "    def __init__(self, inputPath):\n",
    "        self.dfCountryNames = pd.read_excel(os.path.join(input_path, \"countryNames.xlsx\"))\n",
    "        self.dfStateNames = pd.read_excel(os.path.join(input_path, \"stateNames.xlsx\"))\n",
    "        self.dfCityNames = pd.read_excel(os.path.join(input_path, \"cityNames.xlsx\"))\n",
    "        self.dfCountyNames = pd.read_excel(os.path.join(input_path, \"countyNames.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialColumnDetection:\n",
    "    def __init__(self, df, settings):\n",
    "        self.types = [\"longitude\", \"latitude\", \"country\", \"state\", \"city\", \"county\", \"address\", \"zipcode\", \"other location attribute\", \n",
    "         \"not spatial attribute\"]\n",
    "        \n",
    "        self.df = df\n",
    "        # column names\n",
    "        self.columnNames = list(df.columns)\n",
    "        # lower case column names\n",
    "        self.lcColumnNames = []\n",
    "        # lower case column name to orginal name map\n",
    "        self.lowerUpperDict = {}\n",
    "        self.upperLowerDict = {}\n",
    "        # each column is what type\n",
    "        self.colNameType = {}\n",
    "        self.settings = settings\n",
    "    \n",
    "    # change all column names to lower cases\n",
    "    def changeLowerCase(self, ):\n",
    "        for colName in self.columnNames:\n",
    "            lwColName = colName.lower()\n",
    "            self.lcColumnNames.append(lwColName)\n",
    "            self.lowerUpperDict[lwColName] = colName\n",
    "            self.upperLowerDict[colName] = lwColName\n",
    "            \n",
    "    def lcs(self, X, Y): \n",
    "        # find the length of the strings \n",
    "        m = len(X) \n",
    "        n = len(Y) \n",
    "\n",
    "        # declaring the array for storing the dp values \n",
    "        L = [[None]*(n + 1) for i in range(m + 1)] \n",
    "\n",
    "        \"\"\"Following steps build L[m + 1][n + 1] in bottom up fashion \n",
    "        Note: L[i][j] contains length of LCS of X[0..i-1] \n",
    "        and Y[0..j-1]\"\"\"\n",
    "        for i in range(m + 1): \n",
    "            for j in range(n + 1): \n",
    "                if i == 0 or j == 0 : \n",
    "                    L[i][j] = 0\n",
    "                elif X[i-1] == Y[j-1]: \n",
    "                    L[i][j] = L[i-1][j-1]+1\n",
    "                else: \n",
    "                    L[i][j] = max(L[i-1][j], L[i][j-1]) \n",
    "  \n",
    "    # L[m][n] contains the length of LCS of X[0..n-1] & Y[0..m-1] \n",
    "        return L[m][n] \n",
    "    \n",
    "    def editDistance(self, x, y):\n",
    "        return len(x) + len(y) - 2 * lcs(x, y)\n",
    "    \n",
    "    \n",
    "    def detect(self,):\n",
    "        self.changeLowerCase()\n",
    "        for colName in self.columnNames:\n",
    "            if self.detectLongitude(colName.lower(), df[column]):\n",
    "                self.colNameType[colName] = \"longitude\"\n",
    "            elif self.detectLatitude(colName.lower(), df[column]):\n",
    "                self.colNameType[colName] = \"latitude\"\n",
    "            elif self.detectCountry(colName.lower()):\n",
    "                self.colNameType[colName] = \"country\"\n",
    "            elif self.detectState(colName.lower()):\n",
    "                self.colNameType[colName] = \"state\"\n",
    "            elif self.detectCity(colName.lower()):\n",
    "                self.colNameType[colName] = \"city\"\n",
    "            elif self.detectAddress(colName.lower()):\n",
    "                self.colNameType[colName] = \"address\"\n",
    "            elif detectZipcode(colName.lower()):\n",
    "                self.colNameType[colName] = \"zipcode\"\n",
    "            elif detectOtherLocationAttribute(colName.lower()):\n",
    "                self.colNameType[colName] = \"other location attribute\"\n",
    "            else:\n",
    "                self.colNameType[colName] = \"not spatial attribute\"\n",
    "        return self.colNameType\n",
    "            \n",
    "    def commonDetectMethod(self, colName, names, thredshold):\n",
    "        for name in names:\n",
    "            if (colName in name) or (name in colName):\n",
    "                return True\n",
    "        # use fuzz ratio, which uses the idea of levestain distance, we can specify elsewhere\n",
    "        for name in names:\n",
    "            if fuzz.ratio(name, colName) > thredshold:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    #TODO: to be finish, colName passed in is lowercase\n",
    "    def detectLongitude(self, colName, column):\n",
    "        names = [\"longitude\", \"lon\"]\n",
    "        thredshold = 70\n",
    "        if self.commonDetectMethod(colName, names, thredshold):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    #TODO\n",
    "    def detectLatitude(self, colName, column):\n",
    "        names = [\"latitude\", \"lat\"]\n",
    "        thredshold = 70\n",
    "        if self.commonDetectMethod(colName, names, thredshold):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    # list all the country out, count how many of the sample column values are in country list\n",
    "    def detectCountry(self, colName):\n",
    "        # quite similar word\n",
    "        if \"county\" in colName:\n",
    "            return False\n",
    "        names = [\"country\"]\n",
    "        thredshold = 70\n",
    "        if self.commonDetectMethod(colName, names, thredshold):\n",
    "            return True\n",
    "        if self.df[colName].dtype == object:\n",
    "            dfCountryNames = self.settings.dfCountryNames\n",
    "            # sampling and pair wise comparison\n",
    "            sampleSize = 500\n",
    "            columnValuesSample = random.sample(list(df[colName].values), sampleSize)\n",
    "            columnValuesSample = [x for x in columnValuesSample if x == str]\n",
    "            sampleLength = len(columnValuesSample)\n",
    "            # meanning many are nan\n",
    "            if sampleLength / sampleSize < 0.1:\n",
    "                return False\n",
    "            \n",
    "            # get the average length of the values\n",
    "            avgLen = sum( map(len, columnValuesSample) ) / len(columnValuesSample)\n",
    "            \n",
    "            # compare with country code, other wise compare with country full name\n",
    "            if avgLen <= 2.3:\n",
    "                countries = dfCountryNames[\"Code\"].values\n",
    "            else:\n",
    "                countries = dfCountryNames[\"Name\"].values\n",
    "                \n",
    "            # equality count\n",
    "            count = 0\n",
    "            for value in columnValuesSample:\n",
    "                for country in countries:\n",
    "                    if value == country:\n",
    "                        count += 1\n",
    "                        break\n",
    "            if count / sampleLength > 0.6:\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    \n",
    "    # list all the state out, fullname and abbreviation, can use sampling\n",
    "    def detectState(self, colName):\n",
    "        names = [\"state\"]\n",
    "        thredshold = 70\n",
    "        if self.commonDetectMethod(colName, names, thredshold):\n",
    "            return True\n",
    "        if self.df[colName].dtype == object:\n",
    "            dfStateNames = self.settings.dfStateNames\n",
    "            # sampling and pair wise comparison\n",
    "            sampleSize = 500\n",
    "            columnValuesSample = random.sample(list(df[colName].values), sampleSize)\n",
    "            columnValuesSample = [x for x in columnValuesSample if x == str]\n",
    "            sampleLength = len(columnValuesSample)\n",
    "            # meanning many are nan\n",
    "            if sampleLength / sampleSize < 0.1:\n",
    "                return False\n",
    "            \n",
    "            # get the average length of the values\n",
    "            avgLen = sum( map(len, columnValuesSample) ) / len(columnValuesSample)\n",
    "            \n",
    "            # compare with state code, other wise compare with state full name\n",
    "            if avgLen <= 2.3:\n",
    "                states = dfStateNames[\"Code\"].values\n",
    "            else:\n",
    "                states = dfStateNames[\"Name\"].values\n",
    "                \n",
    "            # equality count\n",
    "            count = 0\n",
    "            for value in columnValuesSample:\n",
    "                for state in states:\n",
    "                    if value == state:\n",
    "                        count += 1\n",
    "                        break\n",
    "            if count / sampleLength > 0.6:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    # can use sampling\n",
    "    def detectCity(self, colName):\n",
    "        names = [\"city\", \"town\"]\n",
    "        thredshold = 70\n",
    "        if self.commonDetectMethod(colName, names, thredshold):\n",
    "            return True\n",
    "        if self.df[colName].dtype == object:\n",
    "            dfCityNames = self.settings.dfCityNames\n",
    "            # sampling and pair wise comparison\n",
    "            sampleSize = 500\n",
    "            columnValuesSample = random.sample(list(df[colName].values), sampleSize)\n",
    "            columnValuesSample = [x for x in columnValuesSample if x == str]\n",
    "            sampleLength = len(columnValuesSample)\n",
    "            # meanning many are nan\n",
    "            if sampleLength / sampleSize < 0.1:\n",
    "                return False\n",
    "            \n",
    "            cities = dfCityNames[\"Name\"].values\n",
    "            # equality count\n",
    "            count = 0\n",
    "            for value in columnValuesSample:\n",
    "                for city in cities:\n",
    "                    if value == city:\n",
    "                        count += 1\n",
    "                        break\n",
    "            if count / sampleLength > 0.6:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "        # list all the county out, count how many of the sample column values are in county list. Not country!!!\n",
    "    def detectCounty(self, colName):\n",
    "        # quite similar word\n",
    "        if \"country\" in colName:\n",
    "            return False\n",
    "        names = [\"county\"]\n",
    "        thredshold = 70\n",
    "        if self.commonDetectMethod(colName, names, thredshold):\n",
    "            return True\n",
    "        if self.df[colName].dtype == object:\n",
    "            dfCountyNames = self.settings.dfCountyNames\n",
    "            # sampling and pair wise comparison\n",
    "            sampleSize = 500\n",
    "            columnValuesSample = random.sample(list(df[colName].values), sampleSize)\n",
    "            columnValuesSample = [x for x in columnValuesSample if x == str]\n",
    "            sampleLength = len(columnValuesSample)\n",
    "            # meanning many are nan\n",
    "            if sampleLength / sampleSize < 0.1:\n",
    "                return False\n",
    "            \n",
    "            counties = dfCountyNames[\"Name\"].values\n",
    "            # equality count\n",
    "            count = 0\n",
    "            for value in columnValuesSample:\n",
    "                for county in counties:\n",
    "                    if value == county:\n",
    "                        count += 1\n",
    "                        break\n",
    "            if count / sampleLength > 0.6:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    # need to use sampling\n",
    "    def detectAddress(self, colName):\n",
    "        names = [\"address\"]\n",
    "        thredshold = 70\n",
    "        if self.commonDetectMethod(colName, names, thredshold):\n",
    "            return True\n",
    "        if self.df[colName].dtype == object:\n",
    "            # sampling and pair wise comparison\n",
    "            sampleSize = 500\n",
    "            columnValuesSample = random.sample(list(df[colName].values), sampleSize)\n",
    "            columnValuesSample = [x for x in columnValuesSample if x == str]\n",
    "            sampleLength = len(columnValuesSample)\n",
    "            # meanning many are nan\n",
    "            if sampleLength / sampleSize < 0.1:\n",
    "                return False\n",
    "            \n",
    "            # get the average length of the values\n",
    "            avgLen = sum( map(len, columnValuesSample) ) / len(columnValuesSample)\n",
    "            # probably not address\n",
    "            if avgLen < 5:\n",
    "                return False\n",
    "            \n",
    "            # use regex expression\n",
    "            regexPattern = \"\"\"\n",
    "            \\b\\d{1,6} +.{2,25}\\b(avenue|ave|court|ct|street|st|drive|dr|lane|ln|road|rd|blvd|plaza|parkway|pkwy|boulevard|)[.,]?(.{0,25} +\\b\\d{5}\\b)?\n",
    "            \"\"\"\n",
    "            count = 0\n",
    "            for x in columnValuesSample:\n",
    "                result = re.match(regexPattern, x)\n",
    "                if result != None:\n",
    "                    if result.group() > 10:\n",
    "                        count += 1\n",
    "            if count / sampleLength > 0.6:\n",
    "                return True\n",
    "            \n",
    "            #TODO use the addr_detection package\n",
    "#             try:\n",
    "#                 clf2 = Postal_clf()\n",
    "#                 result = clf2.predict(columnValuesSample)\n",
    "#             except:\n",
    "#                 return False\n",
    "        return False\n",
    "    \n",
    "    # need to use sampling, and regex\n",
    "    def detectZipcode(self, colName):\n",
    "        names = [\"zip\", \"zipcode\", \"code\", \"zcode\", \"postcode\"]\n",
    "        thredshold = 70\n",
    "        if self.commonDetectMethod(colName, names, thredshold):\n",
    "            return True\n",
    "        if self.df[colName].dtype == object:\n",
    "            # sampling and pair wise comparison\n",
    "            sampleSize = 500\n",
    "            columnValuesSample = random.sample(list(df[colName].values), sampleSize)\n",
    "            columnValuesSample = [x for x in columnValuesSample if x == str]\n",
    "            sampleLength = len(columnValuesSample)\n",
    "            # meanning many are nan\n",
    "            if sampleLength / sampleSize < 0.1:\n",
    "                return False\n",
    "            # just us country here, can use other api?\n",
    "            regexPattern = r\"^[0-9]{5}(?:-[0-9]{6})?$\"\n",
    "            matches = []\n",
    "            for x in columnValuesSample:\n",
    "                result = re.match(regexPattern, x)\n",
    "                if result != None:\n",
    "                    matches.append(bool(x))\n",
    "            count = sum([bool(x) for x in matches])\n",
    "            if count / sampleLength > 0.6:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def detectOtherLocationAttribute(self, colName):\n",
    "        names = [\"location\"]\n",
    "        thredshold = 70\n",
    "        if self.commonDetectMethod(colName, names, thredshold):\n",
    "            return True   \n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'safa_'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"safA_\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-fe55116960a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\hewei\\appdata\\local\\programs\\python\\python36\\lib\\random.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, population, k)\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m21\u001b[0m        \u001b[1;31m# size of a small set minus size of an empty list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "random.sample([1,2], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.ratio(\"longitude1\", \"longitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.partial_ratio(\"country\", \"country\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
